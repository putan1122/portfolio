{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Library","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport json\nimport copy\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n#plt\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n%matplotlib inline\nimport seaborn as sns\nimport os, random, sys, time, re\n\n# scaling\nfrom sklearn.preprocessing import RobustScaler, StandardScaler,MinMaxScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.base import BaseEstimator\nfrom sklearn.impute import SimpleImputer\n\n\n#Missing value\nfrom sklearn.impute import KNNImputer\nfrom sklearn.impute import SimpleImputer\n\n#feature\nfrom sklearn.cluster import KMeans\n\n\n#classifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.impute import SimpleImputer\nfrom catboost import Pool, CatBoostClassifier\nimport xgboost\nfrom lightgbm import LGBMClassifier\n\n#loss\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import precision_score, recall_score,accuracy_score\n\n#times\nfrom datetime import date, datetime\n\n#OverSampler\nfrom imblearn.over_sampling import RandomOverSampler\n# SMOTE (Synthetic Minority Over-sampling Technique)\nfrom imblearn.over_sampling import SMOTE\n\n#skf\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom sklearn.preprocessing import KBinsDiscretizer\nimport category_encoders as encoders","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-05T15:38:47.392595Z","iopub.execute_input":"2023-08-05T15:38:47.393359Z","iopub.status.idle":"2023-08-05T15:38:47.411640Z","shell.execute_reply.started":"2023-08-05T15:38:47.393325Z","shell.execute_reply":"2023-08-05T15:38:47.410416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# seed","metadata":{}},{"cell_type":"code","source":"def seed_everything(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n#     torch.manual_seed(seed)\n#     torch.backends.cudnn.benchmark=False\n#     torch.cuda.manual_seed(seed)\n#     torch.backends.cudnn.deterministic = True\n#     torch.use_deterministic_algorithms = True\n    \nseed_everything(seed=40)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T15:38:47.413703Z","iopub.execute_input":"2023-08-05T15:38:47.414122Z","iopub.status.idle":"2023-08-05T15:38:47.427505Z","shell.execute_reply.started":"2023-08-05T15:38:47.414089Z","shell.execute_reply":"2023-08-05T15:38:47.426460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"class Config:\n    BASE_DIR = '/kaggle/input/icr-identify-age-related-conditions'\n    random_state = 42\n    run_para = 'local' #kaggle\n    EJ_encoded='CATBoostENCODE' #intENCODE,dropEJ\n    fillna='muti-fill'   #muti-fill\n    scaling='RobustScaler'#RobustScaler, StandardScaler,MinMaxScaler\n    Sampler='none'  #OverSampler\n    target='Class'\n    binner_features='DU'\ncfg = Config()","metadata":{"execution":{"iopub.status.busy":"2023-08-05T15:38:47.429868Z","iopub.execute_input":"2023-08-05T15:38:47.430198Z","iopub.status.idle":"2023-08-05T15:38:47.438295Z","shell.execute_reply.started":"2023-08-05T15:38:47.430168Z","shell.execute_reply":"2023-08-05T15:38:47.437388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. load the data","metadata":{}},{"cell_type":"code","source":"maindf = pd.read_csv(f'{cfg.BASE_DIR}/train.csv')\ngreeksdf = pd.read_csv(f'{cfg.BASE_DIR}/greeks.csv')\ntestdf = pd.read_csv(f'{cfg.BASE_DIR}/test.csv')\n\n#移除首尾空格\nmaindf.columns      = maindf.columns.str.strip()\ntestdf.columns = testdf.columns.str.strip()","metadata":{"execution":{"iopub.status.busy":"2023-08-05T15:38:47.442354Z","iopub.execute_input":"2023-08-05T15:38:47.442634Z","iopub.status.idle":"2023-08-05T15:38:47.476796Z","shell.execute_reply.started":"2023-08-05T15:38:47.442611Z","shell.execute_reply":"2023-08-05T15:38:47.475947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. EDA ","metadata":{}},{"cell_type":"code","source":"# df_train_numerical = maindf.drop(['Id', 'EJ', 'Class'], axis=1)\n# df_train_numerical.describe(include='all').transpose()","metadata":{"execution":{"iopub.status.busy":"2023-08-05T15:38:47.477913Z","iopub.execute_input":"2023-08-05T15:38:47.478706Z","iopub.status.idle":"2023-08-05T15:38:47.482863Z","shell.execute_reply.started":"2023-08-05T15:38:47.478672Z","shell.execute_reply":"2023-08-05T15:38:47.481814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Histgram for numercial features\n# fig, ax = plt.subplots(11, 5, figsize=(16,30))\n\n# for i in range(0, (len(ax.flatten()))):\n#     sns.histplot(data=df_train_numerical, x =df_train_numerical.iloc[:,i], bins=20, ax=ax[int(i/5),i % 5]) \n# plt.subplots_adjust(hspace=0.5)  \n\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-05T15:38:47.484308Z","iopub.execute_input":"2023-08-05T15:38:47.484999Z","iopub.status.idle":"2023-08-05T15:38:47.494016Z","shell.execute_reply.started":"2023-08-05T15:38:47.484968Z","shell.execute_reply":"2023-08-05T15:38:47.493385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"outliers-Robust Scaler（mitigate the impact of outliers and achieve a more reliable and accurate modeling outcome.）","metadata":{}},{"cell_type":"code","source":"# fig, ax = plt.subplots(11, 5, figsize=(16,30))\n# for i in range(0, (len(ax.flatten()))):\n#     sns.boxplot(x=\"Class\",y=df_train_numerical.columns[i],data=maindf, ax=ax[int(i/5),i % 5])\n# plt.subplots_adjust(wspace=0.3)  \n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-05T15:38:47.495282Z","iopub.execute_input":"2023-08-05T15:38:47.495923Z","iopub.status.idle":"2023-08-05T15:38:47.505447Z","shell.execute_reply.started":"2023-08-05T15:38:47.495894Z","shell.execute_reply":"2023-08-05T15:38:47.504522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.Pre-processing","metadata":{}},{"cell_type":"code","source":"df_numeric_columns =  maindf.drop(['EJ','Id','Class'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T15:38:47.506449Z","iopub.execute_input":"2023-08-05T15:38:47.506824Z","iopub.status.idle":"2023-08-05T15:38:47.517146Z","shell.execute_reply.started":"2023-08-05T15:38:47.506795Z","shell.execute_reply":"2023-08-05T15:38:47.516213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* 3.1.feature enhancement","metadata":{}},{"cell_type":"code","source":"k = 5\nif cfg.run_para == 'kaggle':\n    BNpd = pd.concat([maindf['BN'], testdf['BN']], axis=0, ignore_index=True)\nelif cfg.run_para == 'local':\n    BNpd = maindf['BN'] \n\ndata = BNpd.values.reshape(-1, 1)   #转化为一位数组\nkmodel = KMeans(n_clusters=k)           # k为聚成几类\nkmodel.fit(data)  # 训练模型\nc = pd.DataFrame(kmodel.cluster_centers_, columns=['cc']) #求聚类中心\nc0 = pd.DataFrame({'cc': [0.0]})\nc = pd.concat([c0, c], axis=0, ignore_index=True)\nc = c.sort_values(by='cc').reset_index(drop=True)\n\nfor i in range(c.shape[0] - 1):\n    c.iloc[i]['cc'] = (c.iloc[i]['cc'] + c.iloc[i+1]['cc']) / 2\nc = c.drop(c.index[-1])\n\nc0 = pd.DataFrame({'cc': [0.0]})\ncn = pd.DataFrame({'cc': [max(maindf['BN'].max(), testdf['BN'].max()) * 5]})\nc = pd.concat([c0, c, cn], axis=0, ignore_index=True)\nc = c['cc'].round().astype(int)\nc = c.unique()\nrange_num = c.shape[0] - 1\nc = c.tolist()\n\ntrain_BN = maindf['BN'].values\ntrain_binning = pd.cut(train_BN, c, labels=range(range_num), include_lowest=True).astype(int)\nmaindf['BN_binning'] = train_binning\n\ntest_BN = testdf['BN'].values\ntest_binning = pd.cut(test_BN, c, labels=range(range_num), include_lowest=True).astype(int)\ntestdf['BN_binning'] = test_binning","metadata":{"execution":{"iopub.status.busy":"2023-08-05T15:38:47.518379Z","iopub.execute_input":"2023-08-05T15:38:47.518994Z","iopub.status.idle":"2023-08-05T15:38:47.567945Z","shell.execute_reply.started":"2023-08-05T15:38:47.518963Z","shell.execute_reply":"2023-08-05T15:38:47.567304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def binning_feature(df, feature_name, n_bins=8, strategy=\"quantile\"):\n    kbins = KBinsDiscretizer(n_bins=n_bins, encode=\"ordinal\", strategy=strategy, subsample=None, random_state=40)\n    feature_binned = kbins.fit_transform(df[feature_name].values.reshape(-1, 1))\n    df[f'{feature_name}_binning'] = feature_binned\n# binning_feature(maindf, cfg.binner_features, n_bins=8, strategy=\"quantile\")\n# binning_feature(testdf, cfg.binner_features, n_bins=8, strategy=\"quantile\")","metadata":{"execution":{"iopub.status.busy":"2023-08-05T15:38:47.573680Z","iopub.execute_input":"2023-08-05T15:38:47.574510Z","iopub.status.idle":"2023-08-05T15:38:47.581449Z","shell.execute_reply.started":"2023-08-05T15:38:47.574464Z","shell.execute_reply":"2023-08-05T15:38:47.580447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* 3.2.EJ encoding","metadata":{}},{"cell_type":"code","source":"if cfg.EJ_encoded == 'CATBoostENCODE':\n    CATBoostENCODE = encoders.CatBoostEncoder()\n    categorical_cols = ['EJ']\n    encoder_train = CATBoostENCODE.fit_transform(maindf[categorical_cols], maindf['Class'])\n    maindf.EJ = pd.DataFrame(encoder_train)\n    encoder_test = CATBoostENCODE.transform(testdf[categorical_cols])\n    testdf.EJ = pd.DataFrame(encoder_test)  \nelif cfg.EJ_encoded == 'intENCODE':\n    first_cat = maindf.EJ.unique()[0]\n    maindf.EJ  = maindf.EJ.eq(first_cat).astype('int')\n    testdf.EJ   = testdf.EJ.eq(first_cat).astype('int')\nelif cfg.EJ_encoded == 'dropEJ':\n    maindf=maindf.drop(['EJ'],axis=1)\n    testdf=testdf.drop(['EJ'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T15:38:47.583351Z","iopub.execute_input":"2023-08-05T15:38:47.584251Z","iopub.status.idle":"2023-08-05T15:38:47.608586Z","shell.execute_reply.started":"2023-08-05T15:38:47.584220Z","shell.execute_reply":"2023-08-05T15:38:47.607667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* 3.3.Fillna ","metadata":{}},{"cell_type":"code","source":"if cfg.fillna == 'knn':\n    imputer = KNNImputer(n_neighbors=5)  \n    maindf_none = pd.DataFrame(imputer.fit_transform(maindf[df_numeric_columns.columns]), columns=df_numeric_columns.columns)\n    testdf_none =pd.DataFrame(imputer.fit_transform(testdf[df_numeric_columns.columns]), columns=df_numeric_columns.columns)\n    #testdf_none =pd.DataFrame(imputer.transform(testdf[df_train_numerical.columns]), columns=df_train_numerical.columns)\n   # Replace the imputed columns in the train data sets\n    df_train_2 = maindf.drop(df_numeric_columns.columns, axis=1)\n    maindf = pd.concat([df_train_2, maindf_none], axis=1)\n    # Replace the imputed columns in the test data sets\n    df_test_2 = testdf.drop(df_numeric_columns.columns, axis=1)\n    testdf = pd.concat([df_test_2, testdf_none], axis=1)\nif cfg.fillna == 'muti-fill':\n    maindf['BQ'] = maindf['BQ'].fillna(maindf['BQ'].min())\n    maindf['EL'] = maindf['EL'].fillna(maindf['EL'].mode()[0])\n    maindf['CB'] = maindf['CB'].fillna(maindf['CB'].median())\n    maindf['CC'] = maindf['CC'].fillna(maindf['CC'].mean())\n    maindf['DU'] = maindf['DU'].fillna(maindf['DU'].min())\n    maindf['FC'] = maindf['FC'].fillna(maindf['FC'].mean())\n    maindf['FL'] = maindf['FL'].fillna(maindf['FL'].median())\n    maindf['FS'] = maindf['FS'].fillna(maindf['FS'].mode()[0])\n    maindf['GL'] = maindf['GL'].fillna(maindf['GL'].mode()[0])\n    \n    testdf['BQ'] = testdf['BQ'].fillna(testdf['BQ'].min())\n    testdf['EL'] = testdf['EL'].fillna(testdf['EL'].mode()[0])\n    testdf['CB'] = testdf['CB'].fillna(testdf['CB'].median())\n    testdf['CC'] = testdf['CC'].fillna(testdf['CC'].mean())\n    testdf['DU'] = testdf['DU'].fillna(testdf['DU'].min())\n    testdf['FC'] = testdf['FC'].fillna(testdf['FC'].mean())\n    testdf['FL'] = testdf['FL'].fillna(testdf['FL'].median())\n    testdf['FS'] = testdf['FS'].fillna(testdf['FS'].mode()[0])\n    testdf['GL'] = testdf['GL'].fillna(testdf['GL'].mode()[0])\n    \n    #check\n    imputer = KNNImputer(n_neighbors=5)    \n    df_test_numerical = testdf.drop(['EJ','Id'], axis=1)\n    df_test_2 = testdf.drop(df_test_numerical.columns, axis=1)\n    testdf_none =pd.DataFrame(imputer.fit_transform(testdf[df_test_numerical.columns]), columns=df_test_numerical.columns)\n    testdf = pd.concat([df_test_2, testdf_none], axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T15:38:47.610066Z","iopub.execute_input":"2023-08-05T15:38:47.610692Z","iopub.status.idle":"2023-08-05T15:38:47.662102Z","shell.execute_reply.started":"2023-08-05T15:38:47.610653Z","shell.execute_reply":"2023-08-05T15:38:47.660833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* 3.4.Standarization","metadata":{}},{"cell_type":"code","source":"if cfg.scaling=='RobustScaler':\n    scaler = RobustScaler()\n    index = maindf.index\n    scaler_train = scaler.fit_transform(maindf[df_numeric_columns.columns])\n    scaler_df_train = pd.DataFrame(scaler_train, columns=df_numeric_columns.columns)\n    scaler_df_train.index = index\n    \n    index = testdf.index\n    scaler_test = scaler.transform(testdf[df_numeric_columns.columns])\n    scaler_df_test = pd.DataFrame(scaler_test, columns=df_numeric_columns.columns)\n    scaler_df_test.index = index\n    \n    df_train_2 = maindf.drop(df_numeric_columns.columns, axis=1)\n    maindf = pd.concat ([df_train_2, scaler_df_train], axis=1)\n    \n    df_test_2 = testdf.drop(df_numeric_columns.columns, axis=1)\n    testdf = pd.concat ([df_test_2, scaler_df_test], axis=1)\n    \nelif cfg.scaling=='StandardScaler':\n    scaler = StandardScaler()\n    index = maindf.index\n    scaler_train = scaler.fit_transform(maindf[df_numeric_columns.columns])\n    scaler_df_train = pd.DataFrame(scaler_train, columns=df_numeric_columns.columns)\n    scaler_df_train.index = index\n    \n    index = testdf.index\n    scaler_test = scaler.transform(testdf[df_numeric_columns.columns])\n    scaler_df_test = pd.DataFrame(scaler_test, columns=df_numeric_columns.columns)\n    scaler_df_test.index = index\n    \n    df_train_2 = maindf.drop(df_numeric_columns.columns, axis=1)\n    maindf = pd.concat ([df_train_2, scaler_df_train], axis=1)\n    \n    df_test_2 = df_test_2.drop(df_numeric_columns.columns, axis=1)\n    testdf = pd.concat ([df_test_2, scaler_df_test], axis=1)\n\nelif cfg.scaling=='MinMaxScaler':\n    scaler = MinMaxScaler()\n    index = maindf.index\n    scaler_train = scaler.fit_transform(maindf[df_numeric_columns.columns])\n    scaler_df_train = pd.DataFrame(scaler_train, columns=df_numeric_columns.columns)\n    scaler_df_train.index = index\n    \n    index = testdf.index\n    scaler_test = scaler.transform(testdf[df_numeric_columns.columns])\n    scaler_df_test = pd.DataFrame(scaler_test, columns=df_numeric_columns.columns)\n    scaler_df_test.index = index\n    \n    df_train_2 = maindf.drop(df_numeric_columns.columns, axis=1)\n    maindf = pd.concat ([df_train_2, scaler_df_train], axis=1)\n    \n    df_test_2 = df_test_2.drop(df_numeric_columns.columns, axis=1)\n    testdf = pd.concat ([df_test_2, scaler_df_test], axis=1)\n\nelif cfg.scaling=='none':\n    pass","metadata":{"execution":{"iopub.status.busy":"2023-08-05T15:38:47.663295Z","iopub.execute_input":"2023-08-05T15:38:47.663631Z","iopub.status.idle":"2023-08-05T15:38:47.723732Z","shell.execute_reply.started":"2023-08-05T15:38:47.663600Z","shell.execute_reply":"2023-08-05T15:38:47.722628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4.Prepare Input","metadata":{}},{"cell_type":"code","source":"times = greeksdf.Epsilon.copy()\ntimes[greeksdf.Epsilon != 'Unknown'] = greeksdf.Epsilon[greeksdf.Epsilon != 'Unknown'].map(lambda x: datetime.strptime(x,'%m/%d/%Y').toordinal())\ntimes[greeksdf.Epsilon == 'Unknown'] = np.nan\n\n\nmaindf_times = pd.concat([maindf, times], axis=1)\nmaindf_times['Epsilon'] = maindf_times['Epsilon'].astype(float)\nmaindf_times['Epsilon'] = maindf_times['Epsilon'].fillna(0, )\n\ntarget='Class'\npredictors = [n for n in maindf_times.columns if n != target and n != 'Id']\npred_and_time=maindf_times[predictors]\ny_data=maindf_times['Class']\n\ntestdf['Epsilon'] = pred_and_time['Epsilon'].max() + 1\ntest_pred_and_time =testdf[predictors]","metadata":{"execution":{"iopub.status.busy":"2023-08-05T15:38:47.725105Z","iopub.execute_input":"2023-08-05T15:38:47.725764Z","iopub.status.idle":"2023-08-05T15:38:47.762256Z","shell.execute_reply.started":"2023-08-05T15:38:47.725734Z","shell.execute_reply":"2023-08-05T15:38:47.761016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# smote = SMOTE(sampling_strategy={0: 509, 1: 509})\n# X_smote, y_smote = smote.fit_resample(pred_and_time, y_train)\n# print(\"length of original data is \",len(pred_and_time))\n# print(\"length of oversampled data is \",len(X_smote))","metadata":{"execution":{"iopub.status.busy":"2023-08-05T15:38:47.767464Z","iopub.execute_input":"2023-08-05T15:38:47.767991Z","iopub.status.idle":"2023-08-05T15:38:47.772876Z","shell.execute_reply.started":"2023-08-05T15:38:47.767960Z","shell.execute_reply":"2023-08-05T15:38:47.771713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.balance_logloss","metadata":{}},{"cell_type":"code","source":"def balance_logloss(y_true, y_pred):\n    nc = np.bincount(y_true)\n    return log_loss(y_true, y_pred, sample_weight = 1/nc[y_true], eps=1e-15)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T15:38:47.774568Z","iopub.execute_input":"2023-08-05T15:38:47.775006Z","iopub.status.idle":"2023-08-05T15:38:47.786935Z","shell.execute_reply.started":"2023-08-05T15:38:47.774973Z","shell.execute_reply":"2023-08-05T15:38:47.786018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def balanced_log_loss(y_true, y_pred):\n    N_0 = np.sum(1 - y_true)\n    N_1 = np.sum(y_true)\n    p_1 = np.clip(y_pred, 1e-15, 1 - 1e-15)\n    p_0 = 1 - p_1\n    log_loss_0 = -np.sum((1 - y_true) * np.log(p_0))\n    log_loss_1 = -np.sum(y_true * np.log(p_1))\n    w_0 = 1 / N_0\n    w_1 = 1 / N_1\n    balanced_log_loss = (w_0 * log_loss_0 + w_1 * log_loss_1) / 2\n    return balanced_log_loss \n\ndef lgb_metric(y_true, y_pred):\n    return 'balanced_log_loss', balanced_log_loss(y_true, y_pred), False","metadata":{"execution":{"iopub.status.busy":"2023-08-05T15:38:47.788199Z","iopub.execute_input":"2023-08-05T15:38:47.789232Z","iopub.status.idle":"2023-08-05T15:38:47.797373Z","shell.execute_reply.started":"2023-08-05T15:38:47.789203Z","shell.execute_reply":"2023-08-05T15:38:47.796533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6.Model","metadata":{}},{"cell_type":"markdown","source":"6.1 LGBM","metadata":{}},{"cell_type":"code","source":"class WeightedEns(BaseEstimator):\n    def __init__(self):\n        self.classifiers = [\n            LGBMClassifier(\nboosting_type='goss', \nlearning_rate=0.06733232950390658, \nn_estimators = 50000, \nearly_stopping_round = 300, \nrandom_state=42,\nsubsample=0.6970532011679706,\ncolsample_bytree=0.6055755840633003,\nclass_weight='balanced',\nmetric='binary', \nis_unbalance=True, \nmax_depth=8,\nobjective=\"binary\"\n)]\n    def fit_eval(self, X, y, Xv, yv):\n        cls, y = np.unique(y, return_inverse=True)\n        cls, yv = np.unique(yv, return_inverse=True)\n        self.classes_ = cls\n        f_imp=[]\n        for cl in self.classifiers:\n            cl.fit(X, y,eval_set = [(Xv, yv)],eval_metric =lgb_metric,verbose=0)\n            \n    def predict_proba(self, X):\n        ps = np.stack([cl.predict_proba(X) for cl in self.classifiers])\n        p = np.mean(ps,axis=0)\n        class_0_est_instances = p[:,0].sum()\n        others_est_instances = p[:,1:].sum()\n        new_p = p * np.array([[1/(class_0_est_instances if i==0 else others_est_instances) for i in range(p.shape[1])]])\n        return new_p / np.sum(new_p,axis=1,keepdims=1)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T15:43:38.946408Z","iopub.execute_input":"2023-08-05T15:43:38.946829Z","iopub.status.idle":"2023-08-05T15:43:38.957764Z","shell.execute_reply.started":"2023-08-05T15:43:38.946797Z","shell.execute_reply":"2023-08-05T15:43:38.956855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sk = StratifiedKFold(n_splits=5, shuffle=True, random_state=40)\nscores_train = []\nresult_preds=[]\nrecalls=[]\nprecisions=[]\nval_list=[]\noff=[]\nid_list=[]\nscores=[]\naccuracies=[]\nfor fold_num, (train_index, val_index) in enumerate(sk.split(pred_and_time, y_data)): \n    m = WeightedEns()\n    X_train, X_val = pred_and_time.loc[train_index], pred_and_time.loc[val_index]\n    y_train, y_val = y_data.loc[train_index], y_data.loc[val_index] \n    \n#     smote = SMOTE(sampling_strategy={0: len(y_train[y_train==0]), 1:len(y_train[y_train==0])})\n#     X_train, y_train = smote.fit_resample(X_train, y_train)\n    m.fit_eval(X_train,y_train,X_val,y_val)\n                \n    y_pred_train=m.predict_proba(X_train)\n    preds_train=np.concatenate((y_pred_train[:,:1], np.sum(y_pred_train[:,1:], 1, keepdims=True)), axis=1)[:, 1].reshape(-1)\n    \n    y_pred_val=m.predict_proba(X_val)\n    preds_val =np.concatenate((y_pred_val[:,:1], np.sum(y_pred_val[:,1:], 1, keepdims=True)), axis=1)[:, 1].reshape(-1)\n\n    \n    id_list.append(maindf.loc[val_index, 'Id'])\n    val_list.append(y_val)\n    off.append(preds_val)\n    \n    y_val_pred_binary = (preds_val > 0.5).astype(int)\n    recall = recall_score(y_val, y_val_pred_binary)\n    recalls.append(recall)\n    precision = precision_score(y_val, y_val_pred_binary)\n    precisions.append(precision)\n    \n    accuracy= accuracy_score(y_val, y_val_pred_binary)\n    accuracies.append(accuracy)\n\n    y_pred_test=m.predict_proba(test_pred_and_time)\n    preds_test=np.concatenate((y_pred_test[:,:1], np.sum(y_pred_test[:,1:], 1, keepdims=True)), axis=1)[:, 1].reshape(-1)\n    result_preds.append(preds_test)\n    \n    score = balanced_log_loss(y_val, preds_val)\n    scores.append(score)\nprint('train_local_cv:',scores_train)\nprint(f'train_Mean local_cv: {np.mean(scores_train)}')\n\nprint('test_local_cv:',scores)\nprint(f'test_Mean local_cv: {np.mean(scores)}')\n\nprint('recall:',recalls)\nprint(f'test_Mean recall: {np.mean(recalls)}')\n\nprint('precision:',precisions)\nprint(f'test_Mean precision: {np.mean(precisions)}')\n\nprint('accuracy:',accuracies)\nprint(f'test_Mean accuracy: {np.mean(accuracies)}')","metadata":{"execution":{"iopub.status.busy":"2023-08-05T15:52:26.268056Z","iopub.execute_input":"2023-08-05T15:52:26.269131Z","iopub.status.idle":"2023-08-05T15:52:28.235584Z","shell.execute_reply.started":"2023-08-05T15:52:26.269092Z","shell.execute_reply":"2023-08-05T15:52:28.234563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"off_list = []\nfor array in off:\n    off_list.extend(array)\ny_val_list = []\nfor array in val_list:\n    y_val_list.extend(array)\nid_lists = []\nfor array in id_list:\n    id_lists.extend(array)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T15:52:32.304911Z","iopub.execute_input":"2023-08-05T15:52:32.305300Z","iopub.status.idle":"2023-08-05T15:52:32.311863Z","shell.execute_reply.started":"2023-08-05T15:52:32.305271Z","shell.execute_reply":"2023-08-05T15:52:32.310293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 将class为0和1的数据分别放入不同的列表\nclass_0_pred = [p for c, p in zip(y_val_list, off_list) if c == 0]\nclass_1_pred = [p for c, p in zip(y_val_list, off_list) if c == 1]\n\ndef jitter(data, sigma=0.3):\n    return [x + random.uniform(-sigma, sigma) for x in data]\nplt.figure(figsize=(10, 4))\n# 创建一个横向散点图\nplt.scatter(class_0_pred, jitter([0]*len(class_0_pred)), label='Class 0', edgecolors='blue', marker='o',linewidth=1,facecolors='none')\nplt.scatter(class_1_pred, jitter([1]*len(class_1_pred)), label='Class 1', edgecolors='red', marker='o',linewidth=1,facecolors='none')\n\n# 添加图例和标签\nplt.xlabel('Prediction (pred)')\nplt.yticks([0, 1], ['Class 0', 'Class 1'])\nplt.ylabel('Data Points')\nplt.legend()\n\n# 展示图表\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-05T15:52:34.660850Z","iopub.execute_input":"2023-08-05T15:52:34.661336Z","iopub.status.idle":"2023-08-05T15:52:35.046607Z","shell.execute_reply.started":"2023-08-05T15:52:34.661294Z","shell.execute_reply":"2023-08-05T15:52:35.045634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"table = list(zip(id_lists, y_val_list, off_list))\ndf = pd.DataFrame(table, columns=['id', 'class', 'pred'])\nfile_name = 'lgbm.xlsx'\ndf.to_excel(file_name, index=False, engine='openpyxl')","metadata":{"execution":{"iopub.status.busy":"2023-08-05T15:51:06.116283Z","iopub.execute_input":"2023-08-05T15:51:06.117066Z","iopub.status.idle":"2023-08-05T15:51:06.190145Z","shell.execute_reply.started":"2023-08-05T15:51:06.117023Z","shell.execute_reply":"2023-08-05T15:51:06.189279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"averages = np.mean(result_preds, axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T15:48:04.897328Z","iopub.execute_input":"2023-08-05T15:48:04.898321Z","iopub.status.idle":"2023-08-05T15:48:04.903833Z","shell.execute_reply.started":"2023-08-05T15:48:04.898286Z","shell.execute_reply":"2023-08-05T15:48:04.902776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame(testdf[\"Id\"], columns=[\"Id\"])\nsubmission[\"class_0\"] = 1-averages\nsubmission[\"class_1\"] = averages\nsubmission.to_csv('submission.csv', index=False)\nsubmission_df = pd.read_csv('submission.csv')\nsubmission_df","metadata":{"execution":{"iopub.status.busy":"2023-08-05T15:48:10.372982Z","iopub.execute_input":"2023-08-05T15:48:10.373558Z","iopub.status.idle":"2023-08-05T15:48:10.402426Z","shell.execute_reply.started":"2023-08-05T15:48:10.373517Z","shell.execute_reply":"2023-08-05T15:48:10.401542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from scipy.stats import uniform, randint\n# params = {\n#     'num_leaves': randint(5, 50),\n#     'max_depth': randint(3, 10)\n# }\n\n# lgbm = LGBMClassifier( boosting_type='goss', \n#                       learning_rate=0.06733232950390658, \n#                       n_estimators = 50000, \n#                       random_state=42,\n#                       subsample=0.6970532011679706,\n#                       colsample_bytree=0.6055755840633003,\n#                       class_weight='balanced',\n#                       metric='binary', \n#                       is_unbalance=True, \n#                       max_depth=8,\n#                       objective=\"binary\")","metadata":{"execution":{"iopub.status.busy":"2023-08-05T15:38:50.904586Z","iopub.execute_input":"2023-08-05T15:38:50.904873Z","iopub.status.idle":"2023-08-05T15:38:50.912750Z","shell.execute_reply.started":"2023-08-05T15:38:50.904849Z","shell.execute_reply":"2023-08-05T15:38:50.911642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.model_selection import train_test_split, RandomizedSearchCV\n# folds = 5\n# skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n# lgbm_model = RandomizedSearchCV(lgbm, param_distributions=params, n_iter=2000, scoring='roc_auc', n_jobs=-1, cv=skf.split(X_smote,y_smote), verbose=-1, random_state=1001 )\n# lgbm_model.fit(X_smote, y_smote)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T15:38:50.914348Z","iopub.execute_input":"2023-08-05T15:38:50.917684Z","iopub.status.idle":"2023-08-05T15:38:50.922521Z","shell.execute_reply.started":"2023-08-05T15:38:50.917657Z","shell.execute_reply":"2023-08-05T15:38:50.921546Z"},"trusted":true},"execution_count":null,"outputs":[]}]}